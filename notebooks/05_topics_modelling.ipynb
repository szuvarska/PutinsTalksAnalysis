{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T16:55:32.526193Z",
     "start_time": "2026-01-25T16:55:24.036524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from src.utils import ExperimentLogger, ResourceTracker, set_global_seed\n",
    "logger = ExperimentLogger(experiment_name=\"topic_modeling_bertopic\")\n",
    "set_global_seed(42)"
   ],
   "id": "45fa72ba45e3997",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\PycharmProjects\\PutinsTalksAnalysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging experiments to: reports\\topic_modeling_bertopic_20260125_175532.json\n",
      "Global seed set to: 42\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T16:55:32.567100Z",
     "start_time": "2026-01-25T16:55:32.531690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Configuration\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "DEVICE = \"cuda\" # Forces GPU usage\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "#set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ],
   "id": "25a367c6bbafd187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fd799ab2d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T16:55:32.773788Z",
     "start_time": "2026-01-25T16:55:32.757476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perform_topic_modeling(df: pd.DataFrame, nr_topics: int = 13):\n",
    "    docs = df['transcript_filtered'].dropna().tolist()\n",
    "\n",
    "    # We add specific ones: mr, president, russia, applause, etc\n",
    "    custom_stop_words = list(CountVectorizer(stop_words=\"english\").get_stop_words())\n",
    "    custom_stop_words += [\n",
    "    \"mr\", \"president\", \"russia\", \"russian\", \"federation\",\n",
    "    \"putin\", \"state\", \"year\", \"years\", \"time\", \"today\",\n",
    "    \"work\", \"people\", \"country\", \"applause\", \"translation\",\n",
    "    \"question\", \"answer\", \"think\", \"know\", \"want\", \"thank\",\"like\",\"need\",\n",
    "    \"grate\", \"good\", \"new\"\n",
    "    ]\n",
    "\n",
    "    vectorizer_model = CountVectorizer(stop_words=custom_stop_words, ngram_range=(1, 3)) #ngrams up to 3 words\n",
    "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        vectorizer_model=vectorizer_model, # Use our custom cleaner\n",
    "        nr_topics=nr_topics+1,                      #  + outlier\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "    #outliers reassignment\n",
    "    print(f\"Original outlier count: {topics.count(-1)}\")\n",
    "    new_topics = topic_model.reduce_outliers(docs, topics, strategy=\"embeddings\")\n",
    "    topic_model.update_topics(docs, topics=new_topics, vectorizer_model=vectorizer_model)\n",
    "    print(\"Outliers reassigned\")\n",
    "\n",
    "    #aggregate results\n",
    "    print(\"Aggregating results...\")\n",
    "    df['found_topic_id'] = new_topics\n",
    "    topic_name_map = {}\n",
    "    for topic in set(new_topics):\n",
    "        keywords = [word for word, _ in topic_model.get_topic(topic)][:5]\n",
    "        topic_name_map[topic] = \", \".join(keywords)\n",
    "\n",
    "    # Map the keywords into a new column\n",
    "    df['found_topic_keywords'] = df['found_topic_id'].map(topic_name_map)\n",
    "    print(df[['found_topic_id','found_topic_keywords']].value_counts())\n",
    "    return df\n",
    "\n",
    "def map_topic_names(df: pd.DataFrame, id_to_name_map: dict) -> pd.DataFrame:\n",
    "    if 'found_topic_id' in df.columns:\n",
    "        df['topic_name'] = df['found_topic_id'].map(id_to_name_map)\n",
    "    else:\n",
    "        print(\"Error: 'found_topic_id' column not found. Please check your CSV.\")\n",
    "    return df\n"
   ],
   "id": "3c7a6d6bd34b0f0d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T17:00:31.389542Z",
     "start_time": "2026-01-25T16:55:32.798398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/putins_talks_prepared.csv\",encoding='utf-8')\n",
    "\n",
    "with ResourceTracker(\"Topic Modeling\") as tracker:\n",
    "\n",
    "    df_topcs = perform_topic_modeling(df, nr_topics=13)\n",
    "logger.log_operation(\"Topic Modeling\", tracker.duration, tracker.peak_memory_mb)"
   ],
   "id": "3b47ad1ceb7a2c9f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 17:55:37,115 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 159/159 [00:20<00:00,  7.93it/s]\n",
      "2026-01-25 17:55:58,561 - BERTopic - Embedding - Completed ✓\n",
      "2026-01-25 17:55:58,563 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-01-25 17:56:42,103 - BERTopic - Dimensionality - Completed ✓\n",
      "2026-01-25 17:56:42,103 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-01-25 17:56:42,635 - BERTopic - Cluster - Completed ✓\n",
      "2026-01-25 17:56:42,635 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2026-01-25 17:57:47,419 - BERTopic - Representation - Completed ✓\n",
      "2026-01-25 17:57:47,482 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2026-01-25 17:57:47,576 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-01-25 17:58:55,817 - BERTopic - Representation - Completed ✓\n",
      "2026-01-25 17:58:55,891 - BERTopic - Topic reduction - Reduced number of topics from 118 to 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original outlier count: 1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 17:59:16,502 - BERTopic - WARNING: Using a custom list of topic assignments may lead to errors if topic reduction techniques are used afterwards. Make sure that manually assigning topics is the last step in the pipeline.Note that topic embeddings will also be created through weightedc-TF-IDF embeddings instead of centroid embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers reassigned\n",
      "Aggregating results...\n",
      "found_topic_id  found_topic_keywords                                    \n",
      "0               cooperation, relations, countries, economic, trade          1445\n",
      "1               development, important, just, course, government            1031\n",
      "2               important, great, world, friends, war                        788\n",
      "3               law, rights, important, citizens, colleagues                 292\n",
      "5               sports, sport, olympic, athletes, world                      265\n",
      "4               defence, military, forces, navy, equipment                   233\n",
      "6               economy, percent, economic, government, situation            202\n",
      "9               percent, industry, agricultural, production, support         200\n",
      "10              medical, healthcare, regions, government, important          171\n",
      "7               syria, syrian, relations, countries, international           170\n",
      "8               bank, economy, financial, investment, central bank           142\n",
      "11              housing, regions, government, construction, important        107\n",
      "12              service, customs, customs service, accounts chamber, tax      33\n",
      "Name: count, dtype: int64\n",
      "[Topic Modeling] Finished.\n",
      "   Duration: 297.7641 seconds\n",
      "   Peak Memory: 1430.51 MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T17:00:33.191657Z",
     "start_time": "2026-01-25T17:00:31.622573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_to_name_map = {\n",
    "    0:  \"International Relations & Trade\", # cooperation, relations, economic...\n",
    "    1:  \"Global Politics & History\",       # great, important, world, war...\n",
    "    2:  \"Energy & Industrial Dev\",         # development, energy, gas, industry...\n",
    "    3:  \"Economy & Budget\",                # percent, economy, government, budget...\n",
    "    4:  \"Sports & Olympics\",               # sports, sport, olympic...\n",
    "    5:  \"Defense & Military\",              # defence, military, forces...\n",
    "    6:  \"Healthcare & Regions\",            # medical, regions, situation...\n",
    "    7:  \"Science & Education\",             # research, science, education...\n",
    "    8:  \"Law, Rights & Judiciary\",         # law, rights, important, court...\n",
    "    9:  \"Syria Conflict\",                  # syria, syrian, military...\n",
    "    10: \"Business & Info Dev\",             # important, business, development...\n",
    "    11: \"Housing & Construction\",          # housing, government, regions...\n",
    "    12: \"Customs & Oversight\"              # service, customs, accounts chamber...\n",
    "}\n",
    "df_topics = map_topic_names(df_topcs, id_to_name_map)\n",
    "output_file = \"../data/putins_talks_with_topics\"\n",
    "df_topics.to_csv(output_file, index=False)\n",
    "print(f\"\\nSuccess! Labeled data saved to '{output_file}'\")"
   ],
   "id": "b49d1eeb8c4798c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Labeled data saved to '../data/putins_talks_with_topics'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lets focus on International Relations & Trade",
   "id": "bc3b40cc2bfb291d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T17:01:07.820292Z",
     "start_time": "2026-01-25T17:00:33.273479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_picked_topic = df_topcs[df_topcs['found_topic_id'] == 0]\n",
    "df_subtopics = perform_topic_modeling(df_picked_topic, nr_topics=6)"
   ],
   "id": "375ee1b3624bf758",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 527920d8-10ff-4219-80fd-6ae2669cefff)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "2026-01-25 18:00:37,313 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 46/46 [00:04<00:00, 10.40it/s]\n",
      "2026-01-25 18:00:41,944 - BERTopic - Embedding - Completed ✓\n",
      "2026-01-25 18:00:41,945 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-01-25 18:00:50,680 - BERTopic - Dimensionality - Completed ✓\n",
      "2026-01-25 18:00:50,680 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-01-25 18:00:50,719 - BERTopic - Cluster - Completed ✓\n",
      "2026-01-25 18:00:50,720 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2026-01-25 18:00:55,469 - BERTopic - Representation - Completed ✓\n",
      "2026-01-25 18:00:55,485 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2026-01-25 18:00:55,493 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-01-25 18:01:00,459 - BERTopic - Representation - Completed ✓\n",
      "2026-01-25 18:01:00,477 - BERTopic - Topic reduction - Reduced number of topics from 43 to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original outlier count: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 18:01:02,375 - BERTopic - WARNING: Using a custom list of topic assignments may lead to errors if topic reduction techniques are used afterwards. Make sure that manually assigning topics is the last step in the pipeline.Note that topic embeddings will also be created through weightedc-TF-IDF embeddings instead of centroid embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers reassigned\n",
      "Aggregating results...\n",
      "found_topic_id  found_topic_keywords                                  \n",
      "0               cooperation, relations, countries, economic, trade        831\n",
      "1               relations, cooperation, european, economic, trade         403\n",
      "3               economic, union, trade, eurasian, integration              64\n",
      "2               brics, countries, cooperation, brazil, brics countries     51\n",
      "4               sco, csto, organisation, cooperation, states               51\n",
      "5               argentina, cooperation, relations, latin, countries        45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T17:01:07.867237Z",
     "start_time": "2026-01-25T17:01:07.856040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_to_name_map = {\n",
    "    0: \"International Relations & Trade\",       # cooperation, relations, economic... (Generic)\n",
    "    1: \"National Development & Policy\",         # development, important, course... (Internal)\n",
    "    2: \"Economic Unions & Trade Blocs\",         # economic, countries, union... (EAEU context)\n",
    "    3: \"Ukraine & Crimea Crisis\",               # ukraine, crimea, sevastopol...\n",
    "    4: \"Latin American Relations\",              # argentina, cooperation, brazil...\n",
    "    5: \"Security Alliances (SCO/CSTO)\"          # sco, cooperation, csto...\n",
    "}\n",
    "\n",
    "df_subtopics = map_topic_names(df_subtopics, id_to_name_map)\n",
    "subtopics_list = df_subtopics['topic_name'].tolist()"
   ],
   "id": "7e463f1358d7bed7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T17:01:09.229288Z",
     "start_time": "2026-01-25T17:01:07.867237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_subtopics = []\n",
    "for i in range(len(df_topics)):\n",
    "    if df_topics.loc[i, 'found_topic_id'] == 0:\n",
    "        final_subtopics.append(subtopics_list.pop(0))\n",
    "    else:\n",
    "        final_subtopics.append(df_topics.loc[i, 'topic_name'])\n",
    "\n",
    "df_topics['detailed_topic_name'] = final_subtopics\n",
    "output_file = \"../data/putins_talks_with_detailed_topics\"\n",
    "df_topics.to_csv(output_file, index=False)"
   ],
   "id": "3c8578181f4c7b40",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
