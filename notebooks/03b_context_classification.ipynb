{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T22:23:26.900949Z",
     "start_time": "2026-01-07T22:23:20.376830Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path to import local modules\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "# Import your custom modules\n",
    "from utils import ResourceTracker, set_global_seed, ExperimentLogger\n",
    "from nlp_models import (\n",
    "    load_zero_shot_pipeline, \n",
    "    extract_context_sentences, \n",
    "    classify_sentences_batch, \n",
    "    get_hf_model_metadata,\n",
    "    get_accompanying_terms\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "# Initialize Logging and Seeding\n",
    "logger = ExperimentLogger(log_dir=\"../reports\")\n",
    "set_global_seed(42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging experiments to: ../reports/experiment_20260107_232326.json\n",
      "Global seed set to: 42\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Finding top countries",
   "id": "99f048d95e8c5446"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T22:23:27.841151Z",
     "start_time": "2026-01-07T22:23:26.901999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finding top countries\n",
    "df = pd.read_csv(\"../data/processed/putins_talks_with_countries.csv\")\n",
    "all_countries = df['extracted_countries'].apply(literal_eval).explode().dropna()\n",
    "country_counts = all_countries[all_countries != 'Russia'].value_counts()\n",
    "country_counts"
   ],
   "id": "6dd1e2fcc9956a70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extracted_countries\n",
       "Ukraine           3838\n",
       "China             2964\n",
       "Syria             2384\n",
       "United States     1646\n",
       "Turkey            1468\n",
       "                  ... \n",
       "Greenland            1\n",
       "Virgin Islands       1\n",
       "Seychelles           1\n",
       "Samoa                1\n",
       "Bhutan               1\n",
       "Name: count, Length: 170, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T22:23:27.845675Z",
     "start_time": "2026-01-07T22:23:27.842088Z"
    }
   },
   "cell_type": "code",
   "source": "country_counts.to_csv(\"../data/processed/country_counts.csv\")",
   "id": "38dfbc077fda324c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T22:23:27.849336Z",
     "start_time": "2026-01-07T22:23:27.846657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_countries = country_counts.head(5).index.tolist()\n",
    "top_countries"
   ],
   "id": "716b44b443820471",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ukraine', 'China', 'Syria', 'United States', 'Turkey']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Extracting sentences mentioning chosen countries",
   "id": "99a60b7a2bf3c3d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T22:23:27.852279Z",
     "start_time": "2026-01-07T22:23:27.850092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create target terms\n",
    "target_terms = {\n",
    "    'Poland': ['Poland', 'Polish', 'Poles'],\n",
    "    'Ukraine': ['Ukraine', 'Ukrainian', 'Ukrainians'],\n",
    "    'United States': ['United States', 'USA', 'American', 'Americans', 'U.S.'],\n",
    "    'China': ['China', 'Chinese'],\n",
    "    'Syria': ['Syria', 'Syrian'],\n",
    "    'Russia': ['Russia', 'Russian', 'Russians', 'Soviets', 'Soviet Union', 'USSR', 'Soviet', 'Russian Federation']\n",
    "}"
   ],
   "id": "37b26a159127b13f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-01-07T22:24:42.452462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_countries.append('Poland')\n",
    "for key, terms in target_terms.items():\n",
    "    print(f\"Processing country: {key}\")\n",
    "    # Extract context sentences\n",
    "    with ResourceTracker(\"Sentence Extraction\") as rt:\n",
    "        extracted_data = extract_context_sentences(\n",
    "            texts=df['transcript_filtered'].tolist(), \n",
    "            dates=df['date'].tolist(),\n",
    "            target_terms=terms,\n",
    "            spacy_model_name=\"en_core_web_sm\"\n",
    "        )\n",
    "    logger.log_operation(\"Sentence_Extraction\", rt.duration, rt.peak_memory_mb, {\"count\": len(extracted_data)})\n",
    "    df_sentences = pd.DataFrame(extracted_data)\n",
    "    print(f\"Found {len(df_sentences)} relevant sentences.\")\n",
    "    df_sentences.to_csv(f\"../data/sentences/sentences_{key}.csv\", index=False)\n",
    "    df_sentences.head()"
   ],
   "id": "1d148603fe17ce5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing country: Poland\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Finding accompanying terms",
   "id": "37f00e79660d4c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for key, terms in target_terms.items():\n",
    "    print(f\"Processing country: {key}\")\n",
    "    df_sentences = pd.read_csv(f\"../data/sentences/sentences_{key}.csv\")\n",
    "    for sentence in df_sentences['sentence']:\n",
    "        accompanying_terms = get_accompanying_terms(\n",
    "            sentence, \n",
    "            target_terms=terms\n",
    "        )\n",
    "        df_sentences.at[df_sentences['sentence'] == sentence, 'accompanying_terms'] = str(accompanying_terms)\n",
    "    df_sentences.to_csv(f\"../data/sentences/sentences_{key}_with_terms.csv\", index=False)"
   ],
   "id": "884b5de16243ebfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Classifying sentences using zero-shot classification",
   "id": "882ec8dc684e2998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration\n",
    "LABELS_BASE = [\"partner\", \"enemy\", \"neutral\"]\n",
    "LABELS_SYNONYMS = [\"ally\", \"adversary\", \"unbiased\"]\n",
    "\n",
    "# Load Model\n",
    "model_name = \"facebook/bart-large-mnli\"\n",
    "print(f\"Loading model: {model_name}...\")\n",
    "zs_pipeline = load_zero_shot_pipeline(model_name)\n",
    "\n",
    "# Log Model Metadata for Report\n",
    "meta = get_hf_model_metadata(zs_pipeline)\n",
    "print(f\"Model Architecture: {meta['model_architecture']}\")\n",
    "print(f\"Commit Hash: {meta['commit_hash']}\")"
   ],
   "id": "c4ba7600e4d96bf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for country in top_countries:\n",
    "    print(f\"Classifying sentences for country: {country}\")\n",
    "    df_sentences = pd.read_csv(f\"../data/sentences/sentences_{country}_with_terms.csv\")\n",
    "    \n",
    "    if country == 'Russia':\n",
    "        LABELS_BASE = [\"victim\", \"leader\", \"defender\"]\n",
    "        LABELS_SYNONYMS = [\"casualty\", \"commander\", \"protector\"]\n",
    "    \n",
    "    # Classify sentences in batches\n",
    "    print(\"Running Zero-Shot (Base Labels)...\")\n",
    "    with ResourceTracker(\"ZeroShot_BaseLabels\") as rt:\n",
    "        results_base = classify_sentences_batch(\n",
    "            zs_pipeline, \n",
    "            df_sentences['sentence'].tolist(), \n",
    "            LABELS_BASE\n",
    "        )\n",
    "    \n",
    "    logger.log_operation(\n",
    "        name=\"ZeroShot_Base\",\n",
    "        duration=rt.duration,\n",
    "        memory_mb=rt.peak_memory_mb,\n",
    "        metrics={\"model\": model_name, \"labels\": LABELS_BASE, \"hash\": meta['commit_hash']}\n",
    "    )\n",
    "    \n",
    "    df_sentences['zs_base_label'] = [r['top_label'] for r in results_base]\n",
    "    df_sentences['zs_base_score'] = [r['top_score'] for r in results_base]\n",
    "    \n",
    "    print(\"Running Zero-Shot (Synonym Labels)...\")\n",
    "    with ResourceTracker(\"ZeroShot_SynonymLabels\") as rt:\n",
    "        results_syn = classify_sentences_batch(zs_pipeline, sentences, LABELS_SYNONYMS)\n",
    "    \n",
    "    logger.log_operation(\n",
    "        name=\"ZeroShot_Synonyms\",\n",
    "        duration=rt.duration,\n",
    "        memory_mb=rt.peak_memory_mb,\n",
    "        metrics={\"model\": model_name, \"labels\": LABELS_SYNONYMS}\n",
    "    )\n",
    "    \n",
    "    df_sentences['zs_syn_label'] = [r['top_label'] for r in results_syn]\n",
    "    df_sentences['zs_syn_score'] = [r['top_score'] for r in results_syn]\n",
    "    \n",
    "    # Save classified results\n",
    "    df_sentences.to_csv(f\"../data/sentences/sentences_{country}_classified.csv\", index=False)\n",
    "    print(f\"Saved classified sentences for {country}.\")"
   ],
   "id": "3779662b0ab41b60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Classifying sentences using Gemini and human annotation",
   "id": "4b2ae5dde136ab8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Classification evaluation",
   "id": "3014aba50de741ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Aggregating and saving classification counts",
   "id": "a8934199b3b345dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def aggregate_counts(df, method_col, method_name):\n",
    "    \"\"\"Counts occurrences of each label per country for a given method.\"\"\"\n",
    "    # Group by Country (found_term) and Label\n",
    "    counts = df.groupby(['found_term', method_col]).size().reset_index(name='count')\n",
    "    counts['method'] = method_name\n",
    "    counts.rename(columns={method_col: 'label'}, inplace=True)\n",
    "    return counts"
   ],
   "id": "a7959a3d983e42c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# List of method columns to aggregate\n",
    "methods_to_count = [\n",
    "    ('zs_base_label', 'ZeroShot_Base'),\n",
    "    ('zs_syn_label', 'ZeroShot_Synonym'),\n",
    "    ('ai_prompt_a', 'AI_Prompt_A'),\n",
    "    ('ai_prompt_b', 'AI_Prompt_B')\n",
    "]\n",
    "\n",
    "all_counts = []\n",
    "\n",
    "for col, name in methods_to_count:\n",
    "    if col in df_sentences.columns:\n",
    "        all_counts.append(aggregate_counts(df_sentences, col, name))\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "if all_counts:\n",
    "    df_counts = pd.concat(all_counts, ignore_index=True)\n",
    "    \n",
    "    # Reorder for clarity: Country, Method, Label, Count\n",
    "    df_counts = df_counts[['found_term', 'method', 'label', 'count']]\n",
    "    \n",
    "    print(\"Summary of Classification Counts:\")\n",
    "    display(df_counts.head(15))\n",
    "    \n",
    "    # Save\n",
    "    df_counts.to_csv(\"../data/processed/country_label_counts.csv\", index=False)\n",
    "else:\n",
    "    print(\"No classification columns found to aggregate.\")"
   ],
   "id": "c5756473e499ed10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
