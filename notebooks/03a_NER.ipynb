{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T17:52:11.138185Z",
     "start_time": "2026-01-07T17:52:03.447590Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from utils import ResourceTracker, set_global_seed, ExperimentLogger\n",
    "from nlp_models import load_ner_pipeline, extract_countries_bert\n",
    "from llm_client import GeminiClient\n",
    "\n",
    "# Setup\n",
    "logger = ExperimentLogger()\n",
    "set_global_seed(42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging experiments to: reports/experiment_20260107_185211.json\n",
      "Global seed set to: 42\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Load Data\n",
    "We load the processed speeches."
   ],
   "id": "8f508c8f511eb18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:06:42.482186Z",
     "start_time": "2026-01-07T18:06:41.590857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming data is in root/data\n",
    "try:\n",
    "    df = pd.read_csv('../data/putins_talks_prepared.csv')\n",
    "    # Convert date for sorting/filtering\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    print(f\"Loaded {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found. Please ensure data/putins_talks_prepared.csv exists.\")\n",
    "df.head(2)"
   ],
   "id": "e5c1044446b99b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5079 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                 date persons  \\\n",
       "0 2012-05-07 12:20:00      []   \n",
       "1 2012-05-08 16:00:00      []   \n",
       "\n",
       "                               transcript_unfiltered  kremlin_id  \\\n",
       "0  The ceremony opened with the Russian State Fla...     15224.0   \n",
       "1  State Duma deputies approved Dmitry Medvedev a...     15266.0   \n",
       "\n",
       "                 place                                              title  \\\n",
       "0  The Kremlin, Moscow  Vladimir Putin inaugurated as President of Russia   \n",
       "1               Moscow                         State Duma plenary session   \n",
       "\n",
       "                                              teaser               tags  \\\n",
       "0  The inauguration ceremony took place in the Gr...                 []   \n",
       "1  Vladimir Putin presented the candidacy of Dmit...  ['Civil service']   \n",
       "\n",
       "                                 transcript_filtered  \\\n",
       "0  Citizens of Russia, friends, The inauguration ...   \n",
       "1  Mr Naryshkin, deputies of the Russian parliame...   \n",
       "\n",
       "                                            wordlist  \\\n",
       "0  ['citizen', 'of', 'Russia', ',', 'friend', ','...   \n",
       "1  ['Mr', 'Naryshkin', ',', 'deputy', 'of', 'the'...   \n",
       "\n",
       "                         grouped_tages  \n",
       "0                                   []  \n",
       "1  ['State_Governance_Public_Service']  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>persons</th>\n",
       "      <th>transcript_unfiltered</th>\n",
       "      <th>kremlin_id</th>\n",
       "      <th>place</th>\n",
       "      <th>title</th>\n",
       "      <th>teaser</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript_filtered</th>\n",
       "      <th>wordlist</th>\n",
       "      <th>grouped_tages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-05-07 12:20:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>The ceremony opened with the Russian State Fla...</td>\n",
       "      <td>15224.0</td>\n",
       "      <td>The Kremlin, Moscow</td>\n",
       "      <td>Vladimir Putin inaugurated as President of Russia</td>\n",
       "      <td>The inauguration ceremony took place in the Gr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Citizens of Russia, friends, The inauguration ...</td>\n",
       "      <td>['citizen', 'of', 'Russia', ',', 'friend', ','...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-05-08 16:00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>State Duma deputies approved Dmitry Medvedev a...</td>\n",
       "      <td>15266.0</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>State Duma plenary session</td>\n",
       "      <td>Vladimir Putin presented the candidacy of Dmit...</td>\n",
       "      <td>['Civil service']</td>\n",
       "      <td>Mr Naryshkin, deputies of the Russian parliame...</td>\n",
       "      <td>['Mr', 'Naryshkin', ',', 'deputy', 'of', 'the'...</td>\n",
       "      <td>['State_Governance_Public_Service']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. BERT Extraction (Traditional Pipeline)\n",
    "We extract all mentions (duplicates included) and normalize them using our helper functions.\n"
   ],
   "id": "868baa86b556491d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:48:32.944726Z",
     "start_time": "2026-01-07T17:48:25.261706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model (cached)\n",
    "ner_pipe = load_ner_pipeline()\n",
    "\n",
    "# Run on a random sample first\n",
    "sample_size = 10\n",
    "df_sample = df.sample(n=min(sample_size, len(df)), random_state=42).copy()\n",
    "\n",
    "print(f\"Processing {len(df_sample)} speeches with BERT...\")\n",
    "\n",
    "with ResourceTracker(\"BERT Extraction\") as tracker:\n",
    "    # Apply extraction row by row\n",
    "    df_sample['bert_countries'] = df_sample['transcript_filtered'].apply(\n",
    "        lambda x: extract_countries_bert(x, ner_pipe)\n",
    "    )\n",
    "\n",
    "logger.log_operation(\"BERT Extraction\", tracker.duration, tracker.peak_memory_mb)\n",
    "\n",
    "# Show an example of what was found\n",
    "print(\"Example Output (List of countries found):\")\n",
    "print(df_sample['bert_countries'].iloc[0])\n"
   ],
   "id": "9da3ba9b26af7b07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NER model: dslim/bert-base-NER on device 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 speeches with BERT...\n",
      "[BERT Extraction] Finished.\n",
      "   Duration: 6.8977 seconds\n",
      "   Peak Memory: 14.72 MB\n",
      "Example Output (List of countries found):\n",
      "['Syria', 'Turkey', 'Iran', 'Syria', 'Russia', 'Turkey', 'Iran', 'Syria', 'Syria', 'Syria', 'Iran', 'Turkey', 'Syria', 'Syria']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Modern Pipeline (LLM) vs Manual vs BERT",
   "id": "f603c2a70ac1b644"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:48:32.951343Z",
     "start_time": "2026-01-07T17:48:32.945723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare file for pasting into Gemini Chat\n",
    "cleared_df_sample = df_sample[['date', 'transcript_filtered']].copy()\n",
    "cleared_df_sample.to_csv('../data/samples/ner_gemini_input_sample.csv', index=False)"
   ],
   "id": "7f4562f2412d31b2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:48:32.957815Z",
     "start_time": "2026-01-07T17:48:32.952247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare for manual annotation and pasting Gemini results\n",
    "df_sample['manual_countries'] = \"\" # Empty column to fill\n",
    "df_sample = df_sample[['date', 'transcript_filtered', 'bert_countries', 'manual_countries']]\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../data/samples/ner_validation_sample.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved validation sample to {output_path})\")"
   ],
   "id": "4c5f5e06abbf3aeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation sample to ../data/samples/ner_validation_sample.csv)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Evaluation Logic",
   "id": "17be05bd4a2fed31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T17:55:40.822326Z",
     "start_time": "2026-01-07T17:55:40.809882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reload annotated data\n",
    "try:\n",
    "    annotated_df = pd.read_csv('../data/samples/ner_validation_sample_annotated.csv')\n",
    "    \n",
    "    def parse_list_like(x):\n",
    "        \"\"\"Return a list preserving duplicates for inputs that may be:\n",
    "           - a list\n",
    "           - a string like \"['A', 'B']\"\n",
    "           - a comma-separated string \"A, B, A\"\n",
    "           - NaN/empty -> []\n",
    "        \"\"\"\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "        if isinstance(x, list):\n",
    "            return x\n",
    "        s = str(x).strip()\n",
    "        if not s:\n",
    "            return []\n",
    "        # try literal_eval for python-list-like strings\n",
    "        try:\n",
    "            val = ast.literal_eval(s)\n",
    "            if isinstance(val, list):\n",
    "                return [str(i).strip() for i in val if str(i).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "        # fallback: comma-separated\n",
    "        return [part.strip() for part in s.split(',') if part.strip()]\n",
    "\n",
    "    def calculate_metrics(pred_list, true_str):\n",
    "        true_list = parse_list_like(true_str)\n",
    "        pred_list = parse_list_like(pred_list)\n",
    "    \n",
    "        true_counter = Counter(true_list)\n",
    "        pred_counter = Counter(pred_list)\n",
    "    \n",
    "        # true positives = sum of minimum counts per item\n",
    "        tp = sum((true_counter & pred_counter).values())\n",
    "        total_pred = sum(pred_counter.values())\n",
    "        total_true = sum(true_counter.values())\n",
    "    \n",
    "        fp = total_pred - tp\n",
    "        fn = total_true - tp\n",
    "    \n",
    "        # If both empty, treat as perfect match\n",
    "        if total_pred == 0 and total_true == 0:\n",
    "            return 1.0, 1.0, 1.0\n",
    "    \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        return precision, recall, f1\n",
    "\n",
    "    # Calculate scores\n",
    "    llm_columns = [\"bert_countries\", \"gemini_countries_1\", \"gemini_countries_2\", \"gemini_countries_3\"]\n",
    "    metrics_rows = []\n",
    "    for col in llm_columns:\n",
    "        if col not in annotated_df.columns:\n",
    "            continue\n",
    "        metrics = annotated_df.apply(lambda row: calculate_metrics(row[col], row.get('manual_countries', '')), axis=1)\n",
    "        precision_mean = metrics.apply(lambda x: x[0]).mean()\n",
    "        recall_mean = metrics.apply(lambda x: x[1]).mean()\n",
    "        f1_mean = metrics.apply(lambda x: x[2]).mean()\n",
    "        metrics_rows.append({'method': col, 'precision': precision_mean, 'recall': recall_mean, 'f1': f1_mean})\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_rows, columns=['method', 'precision', 'recall', 'f1'])\n",
    "    print(metrics_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not load/parse annotated file: {e}\")"
   ],
   "id": "28fabb2e17a7195b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               method  precision    recall        f1\n",
      "0      bert_countries   0.831232  0.781806  0.802073\n",
      "1  gemini_countries_1   0.979167  0.994845  0.986625\n",
      "2  gemini_countries_2   0.822648  0.768397  0.770107\n",
      "3  gemini_countries_3   0.974196  0.923785  0.935087\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Extract countries with BERT on full dataset and save",
   "id": "e6b13904223d15b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:30:02.658553Z",
     "start_time": "2026-01-07T18:07:34.622627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model (cached)\n",
    "ner_pipe = load_ner_pipeline()\n",
    "\n",
    "df_with_countries = df.copy()\n",
    "\n",
    "print(f\"Processing {len(df_with_countries)} speeches with BERT...\")\n",
    "\n",
    "with ResourceTracker(\"BERT Extraction\") as tracker:\n",
    "    # Apply extraction row by row\n",
    "    df_with_countries['extracted_countries'] = df_with_countries['transcript_filtered'].apply(\n",
    "        lambda x: extract_countries_bert(x, ner_pipe)\n",
    "    )\n",
    "\n",
    "logger.log_operation(\"BERT Extraction\", tracker.duration, tracker.peak_memory_mb)"
   ],
   "id": "b261078a1d60649c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NER model: dslim/bert-base-NER on device 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5079 speeches with BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT Extraction] Finished.\n",
      "   Duration: 1346.7851 seconds\n",
      "   Peak Memory: 15.34 MB\n",
      "Example Output (List of countries found):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'bert_countries'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/media/marta/Dane/Sem9/NLP/PutinsTalks/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3811\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'bert_countries'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Show an example of what was found\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExample Output (List of countries found):\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf_with_countries\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbert_countries\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m/media/marta/Dane/Sem9/NLP/PutinsTalks/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4113\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4115\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/media/marta/Dane/Sem9/NLP/PutinsTalks/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3815\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3816\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3817\u001B[0m     ):\n\u001B[1;32m   3818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3819\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3820\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3821\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3822\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3823\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'bert_countries'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:24:54.142590Z",
     "start_time": "2026-01-07T19:24:54.140353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show an example of what was found\n",
    "print(\"Example Output (List of countries found):\")\n",
    "print(df_with_countries['extracted_countries'].iloc[0])"
   ],
   "id": "21ecd1d236e314b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Output (List of countries found):\n",
      "['Russia', 'Russia', 'Russia', 'Russia', 'Russia', 'Russian Federation', 'Russian Federation', 'Russia', 'Russian Federation', 'Russia', 'Russia', 'Russia', 'Russia', 'Russia']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:25:01.037344Z",
     "start_time": "2026-01-07T19:24:58.584330Z"
    }
   },
   "cell_type": "code",
   "source": "df_with_countries.to_csv('../data/processed/putins_talks_with_countries.csv', index=False)",
   "id": "4374a9d34ff5dcfc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:30:55.529024Z",
     "start_time": "2026-01-07T19:30:55.517631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Q1: How many times do \"Poland\" and \"Ukraine\" appear?\n",
    "all_countries = [country for sublist in df_with_countries['extracted_countries'] for country in sublist]\n",
    "counts = Counter(all_countries)\n",
    "\n",
    "print(f\"Poland count: {counts.get('Poland', 0)}\")\n",
    "print(f\"Ukraine count: {counts.get('Ukraine', 0)}\")"
   ],
   "id": "e045b80eb8762f0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poland count: 391\n",
      "Ukraine count: 3838\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:31:18.110533Z",
     "start_time": "2026-01-07T19:31:18.107930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Q2: Which country, apart from Russia, appears most frequently?\n",
    "non_russia_counts = {k: v for k, v in counts.items() if k != 'Russia'}\n",
    "if non_russia_counts:\n",
    "    most_freq_country = max(non_russia_counts, key=non_russia_counts.get)\n",
    "    print(f\"Most frequent non-Russia country: {most_freq_country} ({non_russia_counts[most_freq_country]})\")"
   ],
   "id": "2d314250c315c607",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent non-Russia country: Ukraine (3838)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:32:22.676068Z",
     "start_time": "2026-01-07T19:32:22.665572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Q3: List all countries mentioned in speech from date Y\n",
    "target_date = \"2016-04-11\"\n",
    "df_with_countries['date'] = pd.to_datetime(df_with_countries['date'])\n",
    "df_with_countries['date_str'] = df_with_countries['date'].dt.strftime('%Y-%m-%d')\n",
    "countries_on_date = df_with_countries[df_with_countries['date_str'] == target_date]['extracted_countries'].sum()\n",
    "print(f\"Countries on {target_date}: {set(countries_on_date)}\")"
   ],
   "id": "4635c98315e61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries on 2016-04-11: {'Russia', 'China', 'Germany'}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ab5961121ebe12b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
